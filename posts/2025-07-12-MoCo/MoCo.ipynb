{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ad79dffa",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Momentum Contrast (MoCo)\"\n",
    "date: \"2025-07-12\"\n",
    "categories: [self-supervised, contrastive-learning, vision]\n",
    "badges: true\n",
    "description: \"Understanding Momentum Contrastive Learning for Unsupervised Visual Representation Learning\"\n",
    "output-file: 2025-07-12-moco.html\n",
    "author: Jeet Parab\n",
    "toc: true\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3736d4d8",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Introduction\n",
    "MoCo (Momentum Contrast) is a self-supervised learning framework introduced by Facebook AI Research in 2019. It addresses the fundamental challenge of learning visual representations without labeled data by treating contrastive learning as a dictionary look-up problem.\n",
    "\n",
    "The key insight behind MoCo is that contrastive learning can be viewed as training an encoder to perform a dictionary look-up task, where we want to match a query representation with its corresponding key.\n",
    "\n",
    "::: {.callout-note}\n",
    "**Read the original paper:** **He, Kaiming, et al.**  \n",
    "*Momentum Contrast for Unsupervised Visual Representation Learning (MoCo)* (2019)  \n",
    "[arXiv:1911.05722](https://arxiv.org/abs/1911.05722)\n",
    ":::\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6840c11",
   "metadata": {},
   "source": [
    "## Core Concepts of MoCo\n",
    "\n",
    "### 1. Dictionary Look-up Perspective\n",
    "\n",
    "MoCo (Momentum Contrast) reframes contrastive learning as a dictionary look-up task:\n",
    "\n",
    "- **Query (q):** An encoded representation of an augmented image.\n",
    "- **Positive Key (k⁺):** The encoded representation of a *different* augmentation of the *same* image as the query.\n",
    "- **Negative Keys (k⁻):** Encoded representations of *different* images.\n",
    "- **Dictionary:** A dynamic set of keys (representations) used to compare against the query. The goal is to bring the query closer to its positive key while pushing it away from negative keys.\n",
    "\n",
    "### 2. Queue Mechanism\n",
    "\n",
    "MoCo introduces a **queue-based dictionary** to efficiently manage a large set of negative samples:\n",
    "\n",
    "- A **FIFO queue** stores encoded representations (keys) from previous mini-batches.\n",
    "- As new keys are added to the queue, the oldest keys are removed.\n",
    "- This design ensures:\n",
    "  - A **large and consistent dictionary** size independent of the mini-batch size.\n",
    "  - Better utilization of past samples, improving contrastive learning.\n",
    "\n",
    "### 3. Momentum Update\n",
    "\n",
    "Instead of training both encoders via backpropagation, MoCo stabilizes learning with a **momentum update** for the key encoder:\n",
    "\n",
    "- **Query Encoder (`f_q`):** Updated normally using gradient descent.\n",
    "- **Key Encoder (`f_k`):** Updated as an **exponential moving average** of the query encoder:\n",
    "\n",
    "  $$\n",
    "  \\theta_k \\leftarrow m \\cdot \\theta_k + (1 - m) \\cdot \\theta_q\n",
    "  $$\n",
    "\n",
    "- **Momentum Coefficient (`m`):** Typically set to `0.999`, ensuring slow, stable updates.\n",
    "\n",
    "This strategy helps maintain consistent representations for keys, reducing noise in the contrastive learning process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e28d00",
   "metadata": {},
   "source": [
    "## MoCo Architecture and Algorithm\n",
    "\n",
    "### Architecture Components\n",
    "\n",
    "- **Query Encoder (`f_q`)**: A CNN (typically ResNet) that encodes query images.\n",
    "- **Key Encoder (`f_k`)**: A CNN with identical architecture to `f_q`, updated via momentum.\n",
    "- **Queue**: A memory bank storing encoded keys from previous batches.\n",
    "- **Projection Head**: An MLP that projects features into a lower-dimensional embedding space.\n",
    "\n",
    "### Training Process\n",
    "\n",
    "1. Sample a mini-batch of `N` images.\n",
    "2. Apply data augmentation to each image to create *query* and *key* views.\n",
    "3. Encode queries using `f_q` and keys using `f_k`.\n",
    "4. Compute the contrastive loss between each query and all keys in the queue.\n",
    "5. Update the query encoder (`f_q`) via gradient descent.\n",
    "6. Update the key encoder (`f_k`) via momentum update:\n",
    "\n",
    "   $$\n",
    "   \\theta_k \\leftarrow m \\cdot \\theta_k + (1 - m) \\cdot \\theta_q\n",
    "   $$\n",
    "\n",
    "7. Update the queue by enqueuing the new keys and dequeuing the oldest keys.\n",
    "\n",
    "### InfoNCE Loss\n",
    "\n",
    "MoCo uses the **InfoNCE (Noise Contrastive Estimation)** loss:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_q = -\\log \\left( \\frac{\\exp(q \\cdot k^+ / \\tau)}{\\sum_i \\exp(q \\cdot k_i / \\tau)} \\right)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $q$: Query representation  \n",
    "- $k^+$: Positive key representation  \n",
    "- $k_i$: All keys in the dictionary (including positive and negatives)  \n",
    "- $\\tau$: Temperature parameter  \n",
    "- $\\cdot$: Dot product (cosine similarity after L2 normalization)\n",
    "\n",
    "![MoCo Architecture](/assets/MoCo.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a794ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MoCo Implementation in PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MoCo(nn.Module):\n",
    "    def __init__(self, base_encoder, dim=128, K=65536, m=0.999, T=0.07):\n",
    "        \"\"\"\n",
    "        MoCo: Momentum Contrast for Unsupervised Visual Representation Learning\n",
    "\n",
    "        Args:\n",
    "            base_encoder: backbone CNN architecture (ResNet)\n",
    "            dim: feature dimension for contrastive learning\n",
    "            K: queue size (number of negative samples)\n",
    "            m: momentum coefficient for key encoder update\n",
    "            T: temperature parameter for InfoNCE loss\n",
    "        \"\"\"\n",
    "        super(MoCo, self).__init__()\n",
    "        self.K = K\n",
    "        self.m = m\n",
    "        self.T = T\n",
    "\n",
    "        # Create query and key encoders\n",
    "        self.encoder_q = base_encoder(num_classes=dim)\n",
    "        self.encoder_k = base_encoder(num_classes=dim)\n",
    "\n",
    "        # Initialize key encoder parameters with query encoder\n",
    "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
    "            param_k.data.copy_(param_q.data)\n",
    "            param_k.requires_grad = False  # Key encoder is not updated by gradient\n",
    "\n",
    "        # Create the queue for storing keys\n",
    "        self.register_buffer(\"queue\", torch.randn(dim, K))\n",
    "        self.queue = nn.functional.normalize(self.queue, dim=0)\n",
    "\n",
    "        # Queue pointer for circular buffer\n",
    "        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _momentum_update_key_encoder(self):\n",
    "        \"\"\"\n",
    "        Momentum update of the key encoder\n",
    "\n",
    "        \"\"\"\n",
    "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
    "            param_k.data = param_k.data * self.m + param_q.data * (1. - self.m)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _dequeue_and_enqueue(self, keys):\n",
    "        \"\"\"\n",
    "        Update the queue by dequeuing old keys and enqueuing new keys\n",
    "        \"\"\"\n",
    "        batch_size = keys.shape[0]\n",
    "        ptr = int(self.queue_ptr)\n",
    "        assert self.K % batch_size == 0\n",
    "        self.queue[:, ptr:ptr + batch_size] = keys.transpose(0, 1)\n",
    "        ptr = (ptr + batch_size) % self.K  # Move pointer\n",
    "        self.queue_ptr[0] = ptr\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _batch_shuffle_ddp(self, x):\n",
    "        \"\"\"\n",
    "        Batch shuffle for distributed training\n",
    "        This prevents information leakage between query and key encoders\n",
    "        \"\"\"\n",
    "        batch_size_this = x.shape[0]\n",
    "        x_gather = concat_all_gather(x)\n",
    "        batch_size_all = x_gather.shape[0]\n",
    "        num_gpus = batch_size_all // batch_size_this\n",
    "        idx_shuffle = torch.randperm(batch_size_all).cuda()\n",
    "        torch.distributed.broadcast(idx_shuffle, src=0)\n",
    "        idx_unshuffle = torch.argsort(idx_shuffle)\n",
    "        gpu_idx = torch.distributed.get_rank()\n",
    "        idx_this = idx_shuffle.view(num_gpus, -1)[gpu_idx]\n",
    "        return x_gather[idx_this], idx_unshuffle\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _batch_unshuffle_ddp(self, x, idx_unshuffle):\n",
    "        \"\"\"\n",
    "        Undo batch shuffle for distributed training\n",
    "        \"\"\"\n",
    "        batch_size_this = x.shape[0]\n",
    "        x_gather = concat_all_gather(x)\n",
    "        batch_size_all = x_gather.shape[0]\n",
    "        num_gpus = batch_size_all // batch_size_this\n",
    "        gpu_idx = torch.distributed.get_rank()\n",
    "        idx_this = idx_unshuffle.view(num_gpus, -1)[gpu_idx]\n",
    "        return x_gather[idx_this]\n",
    "\n",
    "    def forward(self, im_q, im_k):\n",
    "        \"\"\"\n",
    "        Forward pass for MoCo\n",
    "\n",
    "        Args:\n",
    "            im_q: query images\n",
    "            im_k: key images\n",
    "\n",
    "        Returns:\n",
    "            logits: logits for InfoNCE loss\n",
    "            labels: labels for InfoNCE loss\n",
    "        \"\"\"\n",
    "        # Compute query features\n",
    "        q = self.encoder_q(im_q)  # queries: NxC\n",
    "        q = nn.functional.normalize(q, dim=1)\n",
    "\n",
    "        # Compute key features\n",
    "        with torch.no_grad():  # No gradient for key encoder\n",
    "            self._momentum_update_key_encoder()  # Update key encoder\n",
    "            im_k, idx_unshuffle = self._batch_shuffle_ddp(im_k)\n",
    "            k = self.encoder_k(im_k)  # keys: NxC\n",
    "            k = nn.functional.normalize(k, dim=1)\n",
    "            k = self._batch_unshuffle_ddp(k, idx_unshuffle)\n",
    "\n",
    "        # Compute logits\n",
    "        l_pos = torch.einsum('nc,nc->n', [q, k]).unsqueeze(-1)\n",
    "        l_neg = torch.einsum('nc,ck->nk', [q, self.queue.clone().detach()])\n",
    "        logits = torch.cat([l_pos, l_neg], dim=1)\n",
    "        logits /= self.T\n",
    "        labels = torch.zeros(logits.shape[0], dtype=torch.long).cuda()\n",
    "        self._dequeue_and_enqueue(k)\n",
    "        return logits, labels\n",
    "\n",
    "# Utility function for distributed training\n",
    "@torch.no_grad()\n",
    "def concat_all_gather(tensor):\n",
    "    \"\"\"\n",
    "    Performs all_gather operation on the provided tensors\n",
    "    \"\"\"\n",
    "    tensors_gather = [torch.ones_like(tensor) for _ in range(torch.distributed.get_world_size())]\n",
    "    torch.distributed.all_gather(tensors_gather, tensor, async_op=False)\n",
    "    output = torch.cat(tensors_gather, dim=0)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6ee943",
   "metadata": {},
   "source": [
    "## Training Loop Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11284ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "def main():\n",
    "    import torchvision.models as models\n",
    "\n",
    "    # Create ResNet-50 base encoder\n",
    "    def resnet50_encoder(num_classes=128):\n",
    "        model = models.resnet50(pretrained=False)\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Linear(model.fc.in_features, model.fc.in_features),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(model.fc.in_features, num_classes)\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    # Initialize MoCo model\n",
    "    model = MoCo(resnet50_encoder, dim=128, K=65536, m=0.999, T=0.07)\n",
    "\n",
    "    # Setup optimizer \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.03, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(200):\n",
    "        train_moco(model, train_loader, optimizer, epoch, device)\n",
    "        # Add validation and checkpointing as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b5b103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation typically used with MoCo\n",
    "def get_moco_augmentation():\n",
    "    from torchvision import transforms\n",
    "    # MoCo v1 augmentation\n",
    "    augmentation = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224, scale=(0.2, 1.0)),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        transforms.ColorJitter(0.4, 0.4, 0.4, 0.4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    return augmentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547509a3",
   "metadata": {},
   "source": [
    "## MoCo vs SimCLR\n",
    "\n",
    "| Aspect                     | MoCo                                                                 | SimCLR                                                                 |\n",
    "|----------------------------|----------------------------------------------------------------------|------------------------------------------------------------------------|\n",
    "| **1. Dictionary Management** | Queue-based dictionary with large, consistent size<br>Independent of batch size<br>Memory efficient | Uses within-batch negatives only<br>Requires large batch sizes<br>Memory intensive |\n",
    "| **2. Encoder Architecture**  | Two encoders: query (`f_q`) and key (`f_k`)<br>Momentum update: $$\\theta_k \\leftarrow m \\cdot \\theta_k + (1 - m) \\cdot \\theta_q$$<br>Asymmetric design | Single encoder for all samples<br>Symmetric design<br>No momentum update |\n",
    "| **3. Training Dynamics**     | Stable training with momentum<br>Diverse negatives via queue<br>Robust to batch size | Requires large batches<br>All samples updated together<br>More sensitive to batch size |\n",
    "| **4. Computational Requirements** | Lower memory footprint<br>Efficient for small batches<br>Works on modest hardware | High memory requirements<br>Needs multiple GPUs<br>Heavy batch computations |\n",
    "| **5. Augmentation Strategy** | Initially simple augmentations<br>MoCo v2 adopts stronger ones<br>Less dependent on augmentation | Strong augmentations essential<br>Uses heavy transforms (blur, color distortions)<br>Performance depends on augmentation strength |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664c4bb5",
   "metadata": {},
   "source": [
    "## Summary and Practical Recommendations\n",
    "\n",
    "### When to Choose MoCo:\n",
    "- Limited computational resources \n",
    "- Suitable for academic research or prototyping environments\n",
    "- Preferred when stable training is important\n",
    "- Flexible with varying batch sizes\n",
    "- Enables faster experimentation cycles\n",
    "\n",
    "### When to Choose SimCLR:\n",
    "- Abundant computational resources \n",
    "- Ideal for production environments with large-scale data\n",
    "- Needed when maximum performance is a priority\n",
    "- Well-suited for large-scale industrial applications\n",
    "- Works best when strong augmentation pipelines are already established\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. MoCo democratizes contrastive learning by making it accessible with limited resources  \n",
    "2. SimCLR achieves strong performance but requires significant computational investment  \n",
    "3. The two methods are complementary, serving different use cases  \n",
    "4. MoCo's queue mechanism is an efficient solution to the negative sampling problem  \n",
    "5. SimCLR’s simplicity makes it easier to understand and adapt to specific applications  \n",
    "\n",
    "The choice between MoCo and SimCLR depends on your available resources and performance needs. MoCo strikes a practical balance between efficiency and effectiveness, while SimCLR excels when compute and scale are not limiting factors.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
